# coding: utf-8
# @æ—¶é—´   : 2021/8/15 2:53 ä¸‹åˆ
# @ä½œè€…   : æ–‡å±±
# @é‚®ç®±   : wolaizhinidexin@163.com
# @ä½œç”¨   : åå‘ä¼ æ’­
# @æ–‡ä»¶   : Backpropagation_1.py
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import loadmat
import scipy.optimize as opt
from sklearn.metrics import classification_report  # è¿™ä¸ªåŒ…æ˜¯è¯„ä»·æŠ¥å‘Š
from sklearn.preprocessing import OneHotEncoder

"""
L->ç½‘ç»œå±‚æ•°ï¼›S_i -> ç¥ç»å…ƒçš„ä¸ªæ•°ï¼›S_l -> è¾“å‡ºå±‚çš„ç¥ç»å…ƒä¸ªæ•°ï¼›
å°†ç¥ç»ç½‘ç»œçš„åˆ†ç±»å®šä¹‰ä¸ºä¸¤ç§æƒ…å†µ:äºŒç±»åˆ†ç±»å’Œå¤šç±»åˆ†ç±»
äºŒç±»åˆ†ç±»:S_l = 0 , y = 0 æˆ–æ‰1è¡¨ç¤ºé‚£ä¸€ç±»ï¼›
Kç±»åˆ†ç±»ï¼šS_l = k, y_i = 1è¡¨ç¤ºåˆ†ç±»åˆ°é‚£ä¸ªiç±»ï¼›

é€»è¾‘å›å½’çš„ä»£ä»·å‡½æ•°ï¼š
                                 m
        Cost(hÎ¸(x),y) = -1/m * [ âˆ‘ y^i * log(hÎ¸(x^i)) + (1 - y^i) * log(1 - hÎ¸(x^i)]
                                i=1
                                    m
        JÎ¸ = Cost(hÎ¸(x),y) + l/2m * âˆ‘ Î¸_j^2
                                    j=1
å› ä¸ºæ­¤æ—¶ï¼ŒhÎ¸(x^i) å¯èƒ½æ˜¯ hğœƒ(ğ‘¥) âˆˆ R^k,å¹¶ä¸”(hğœƒ(ğ‘¥))^i = ğ‘–^ğ‘¡h è¾“å‡ºï¼Œæ‰€ä»¥æ­¤æ—¶ä»£ä»·å‡½æ•°ä¸ºï¼š

                 1    m    k                                                                   l   L-1 S_l s_l+1
        Jğ›© = - â€”â€”â€”â€” [ âˆ‘    âˆ‘     y_k^i * log(hğ›©(x^i))_k + (1 - y_k^i) * log(1 - hğ›©(x^i))_k] + â€”â€”â€”â€” âˆ‘   âˆ‘   âˆ‘     ğ›©_ij^l ** 2
                m     i=1  k=1                                                                 2m  l=1 i=1 j=1

å¯¹äºæ¯ä¸€è¡Œç‰¹å¾ï¼Œæˆ‘ä»¬éƒ½ä¼šç»™å‡ºğ¾ä¸ªé¢„æµ‹ï¼ŒåŸºæœ¬ä¸Šæˆ‘ä»¬å¯ä»¥åˆ©ç”¨å¾ªç¯ï¼Œå¯¹æ¯ä¸€è¡Œç‰¹å¾éƒ½é¢„æµ‹ğ¾ä¸ªä¸åŒç»“æœï¼Œç„¶ååœ¨åˆ©ç”¨å¾ªç¯åœ¨ğ¾ä¸ªé¢„æµ‹ä¸­é€‰æ‹©å¯èƒ½æ€§æœ€é«˜çš„ä¸€ä¸ªï¼Œ
å°†å…¶ä¸ğ‘¦ä¸­çš„å®é™…æ•°æ®è¿›è¡Œæ¯”è¾ƒ
                    âˆ‚
åå‘ä¼ ä¼ æ’­çš„ç›®çš„æ˜¯æ±‚ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” J(ğ›©)çš„å€¼ï¼Œå³ä»l_laståˆ°l2ä¸­çš„æœ€å°è¯¯å·®ã€‚é¦–å…ˆè®¡ç®—æœ€åä¸€å±‚çš„è¯¯å·®ï¼Œç„¶åå†ä¸€å±‚ä¸€å±‚åå‘æ±‚å‡ºå„å±‚çš„è¯¯å·®ï¼Œç›´åˆ°å€’æ•°ç¬¬äºŒå±‚
                  âˆ‚ğ›©_ij^l
-----------------------------------------------------------------------------------------------------------------------
å‡è®¾ k = 4,S_l = 4, l = 4ï¼Œåˆ™å‰å‘ä¼ æ’­ä¸ºï¼š
a1 = x
z2 = a1 * ğ›©1
a2 = g(z2)
-----------
z3 = a2 * ğ›©2
a3 = g(z3)
-----------
z4 = a3 * ğ›©3
a4 = g(z4) = hğ›©(x)
æˆ‘ä»¬ä»æœ€åä¸€å±‚çš„è¯¯å·®å¼€å§‹è®¡ç®—ï¼Œè¯¯å·®æ˜¯æ¿€æ´»å•å…ƒçš„é¢„æµ‹,a_k^4 - y^kä¹‹é—´çš„è¯¯å·®ï¼Œè¡¨ç¤ºä¸ºğ›¿^4 = a_k^4 - y
åˆ©ç”¨è¿™ä¸ªè¯¯å·®å€¼æ¥è®¡ç®—å‰ä¸€å±‚çš„è¯¯å·®:
ğ›¿(3) = ğ›©3^T ğ›¿^4  * g'(z3), g'(z3)æ˜¯Så‹å‡½æ•°çš„å¯¼æ•°ï¼Œğ‘”â€²(ğ‘§(3)) = ğ‘(3) âˆ— (1 âˆ’ ğ‘(3))ã€‚ ğ›©3^T ğ›¿^4æƒé‡å¯¼è‡´çš„è¯¯å·®çš„å’Œã€‚

ğ›¿(2) = ğ›©2^T ğ›¿^3  * g'(z2)

å› ä¸ºç¬¬ä¸€å±‚æ˜¯è¾“å…¥å˜é‡ï¼Œä¸å­˜åœ¨è¯¯å·®ã€‚æˆ‘ä»¬æœ‰äº†æ‰€æœ‰çš„è¯¯å·®çš„è¡¨è¾¾å¼åï¼Œä¾¿å¯ä»¥è®¡ç®—ä»£ ä»·å‡½æ•°çš„åå¯¼æ•°äº†ï¼Œå‡è®¾ğœ† = 0ï¼Œå³æˆ‘ä»¬ä¸åšä»»ä½•æ­£åˆ™åŒ–å¤„ç†æ—¶æœ‰ï¼š
    âˆ‚
 â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” J(ğ›©) = a_j^l * ğ›¿_i^l + 1
  âˆ‚ğ›©_ij^l
ğ‘™ ä»£è¡¨ç›®å‰æ‰€è®¡ç®—çš„æ˜¯ç¬¬å‡ å±‚ã€‚
ğ‘— ä»£è¡¨ç›®å‰è®¡ç®—å±‚ä¸­çš„æ¿€æ´»å•å…ƒçš„ä¸‹æ ‡ï¼Œä¹Ÿå°†æ˜¯ä¸‹ä¸€å±‚çš„ç¬¬ğ‘—ä¸ªè¾“å…¥å˜é‡çš„ä¸‹æ ‡ã€‚
ğ‘– ä»£è¡¨ä¸‹ä¸€å±‚ä¸­è¯¯å·®å•å…ƒçš„ä¸‹æ ‡ï¼Œæ˜¯å—åˆ°æƒé‡çŸ©é˜µä¸­ç¬¬ğ‘–è¡Œå½±å“çš„ä¸‹ä¸€å±‚ä¸­çš„è¯¯å·®å•å…ƒçš„ä¸‹æ ‡ã€‚
-----------------------------------------------------------------------------------------------------------------------
å¦‚æœæˆ‘ä»¬è€ƒè™‘æ­£åˆ™åŒ–å¤„ç†ï¼Œå¹¶ä¸”æˆ‘ä»¬çš„è®­ç»ƒé›†æ˜¯ä¸€ä¸ªç‰¹å¾çŸ©é˜µè€Œéå‘é‡ã€‚åœ¨ä¸Šé¢çš„ç‰¹æ®Šæƒ…å†µä¸­ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ¯ä¸€å±‚çš„è¯¯å·®å•å…ƒæ¥è®¡ç®—ä»£ä»·å‡½æ•°çš„åå¯¼æ•°ã€‚
åœ¨æ›´ä¸ºä¸€èˆ¬çš„æƒ…å†µä¸­ï¼Œ æˆ‘ä»¬åŒæ ·éœ€è¦è®¡ç®—æ¯ä¸€å±‚çš„è¯¯å·®å•å…ƒï¼Œä½†æ˜¯æˆ‘ä»¬éœ€è¦ä¸ºæ•´ä¸ªè®­ç»ƒé›†è®¡ç®—è¯¯å·®å•å…ƒï¼Œæ­¤æ—¶çš„è¯¯å·®å•å…ƒä¹Ÿæ˜¯ä¸€ä¸ªçŸ©é˜µ.
æˆ‘ä»¬ç”¨ğ›¥_ij^(ğ‘™)æ¥è¡¨ç¤ºè¿™ä¸ªè¯¯å·®çŸ©é˜µã€‚ç¬¬ ğ‘™ å±‚çš„ç¬¬ ğ‘– ä¸ªæ¿€æ´»å•å…ƒå—åˆ°ç¬¬ğ‘—ä¸ªå‚æ•°å½±å“è€Œå¯¼è‡´çš„è¯¯å·®ã€‚
åˆ™æˆ‘ä»¬çš„ç®—æ³•è¡¨ç¤ºä¸ºï¼š
for x in range(m):
    set a^i = x^i
    ğ›¿^l = a^l - y^i
    ğ›¥_ij^(ğ‘™) = ğ›¥_ij^(ğ‘™) +  a_j^l * ğ›¿_i^l + 1
å³é¦–å…ˆç”¨æ­£å‘ä¼ æ’­æ–¹æ³•è®¡ç®—å‡ºæ¯ä¸€å±‚çš„æ¿€æ´»å•å…ƒï¼Œåˆ©ç”¨è®­ç»ƒé›†çš„ç»“æœä¸ç¥ç»ç½‘ç»œé¢„æµ‹çš„ ç»“æœæ±‚å‡ºæœ€åä¸€å±‚çš„è¯¯å·®ï¼Œç„¶ååˆ©ç”¨è¯¥è¯¯å·®è¿ç”¨åå‘ä¼ æ’­æ³•è®¡ç®—å‡ºç›´è‡³ç¬¬äºŒå±‚çš„æ‰€
æœ‰è¯¯å·®ã€‚
åœ¨æ±‚å‡ºäº†ğ›¥_ij^(ğ‘™)ä¹‹åï¼Œæˆ‘ä»¬ä¾¿å¯ä»¥è®¡ç®—ä»£ä»·å‡½æ•°çš„åå¯¼æ•°äº†ï¼Œè®¡ç®—æ–¹æ³•å¦‚ä¸‹:

D_ij^(ğ‘™) := 1/m ğ›¥_ij^(ğ‘™) + â‹‹ ğ›©_ij^(l), if j != 0
D_ij^(ğ‘™) := 1/m ğ›¥_ij^(ğ‘™),              if j  = 0
-----------------------------------------------------------------------------------------------------------------------
æ¢¯åº¦çš„æ•°å€¼æ£€éªŒï¼š
å½“æˆ‘ä»¬å¯¹ä¸€ä¸ªè¾ƒä¸ºå¤æ‚çš„æ¨¡å‹(ä¾‹å¦‚ç¥ç»ç½‘ç»œ)ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æ—¶ï¼Œå¯èƒ½ä¼šå­˜åœ¨ä¸€äº› ä¸å®¹æ˜“å¯Ÿè§‰çš„é”™è¯¯ï¼Œæ„å‘³ç€ï¼Œè™½ç„¶ä»£ä»·çœ‹ä¸Šå»åœ¨ä¸æ–­å‡å°ï¼Œä½†æœ€ç»ˆçš„ç»“æœå¯èƒ½å¹¶ä¸æ˜¯
æœ€ä¼˜è§£ã€‚
å¯¹æ¢¯åº¦çš„ä¼°è®¡é‡‡ç”¨çš„æ–¹æ³•æ˜¯åœ¨ä»£ä»·å‡½æ•°ä¸Šæ²¿ç€åˆ‡çº¿çš„æ–¹å‘é€‰æ‹©ç¦»ä¸¤ä¸ªéå¸¸è¿‘çš„ç‚¹ç„¶å è®¡ç®—ä¸¤ä¸ªç‚¹çš„å¹³å‡å€¼ç”¨ä»¥ä¼°è®¡æ¢¯åº¦ã€‚å³å¯¹äºæŸä¸ªç‰¹å®šçš„ ğœƒï¼Œ
æˆ‘ä»¬è®¡ç®—å‡ºåœ¨ ğœƒ-ğœ€ å¤„å’Œ ğœƒ+ğœ€ çš„ ä»£ä»·å€¼(ğœ€æ˜¯ä¸€ä¸ªéå¸¸å°çš„å€¼ï¼Œé€šå¸¸é€‰å– 0.001)ï¼Œç„¶åæ±‚ä¸¤ä¸ªä»£ä»·çš„å¹³å‡ï¼Œç”¨ä»¥ä¼°è®¡åœ¨ ğœƒ å¤„çš„ä»£ä»·å€¼
-----------------------------------------------------------------------------------------------------------------------
éšæœºåˆå§‹åŒ–ï¼š
ä»»ä½•ä¼˜åŒ–ç®—æ³•éƒ½éœ€è¦ä¸€äº›åˆå§‹çš„å‚æ•°ã€‚åˆ°ç›®å‰ä¸ºæ­¢æˆ‘ä»¬éƒ½æ˜¯åˆå§‹æ‰€æœ‰å‚æ•°ä¸º 0ï¼Œè¿™æ ·çš„ åˆå§‹æ–¹æ³•å¯¹äºé€»è¾‘å›å½’æ¥è¯´æ˜¯å¯è¡Œçš„ï¼Œä½†æ˜¯å¯¹äºç¥ç»ç½‘ç»œæ¥è¯´æ˜¯ä¸å¯è¡Œçš„ã€‚
å¦‚æœæˆ‘ä»¬ä»¤æ‰€æœ‰ çš„åˆå§‹å‚æ•°éƒ½ä¸º 0ï¼Œè¿™å°†æ„å‘³ç€æˆ‘ä»¬ç¬¬äºŒå±‚çš„æ‰€æœ‰æ¿€æ´»å•å…ƒéƒ½ä¼šæœ‰ç›¸åŒçš„å€¼ã€‚åŒç†ï¼Œå¦‚æœæˆ‘ ä»¬åˆå§‹æ‰€æœ‰çš„å‚æ•°éƒ½ä¸ºä¸€ä¸ªé 0 çš„æ•°ï¼Œç»“æœä¹Ÿæ˜¯ä¸€æ ·çš„ã€‚
æˆ‘ä»¬é€šå¸¸åˆå§‹å‚æ•°ä¸ºæ­£è´Ÿğœ€ä¹‹é—´çš„éšæœºå€¼

å°ç»“ä¸€ä¸‹ä½¿ç”¨ç¥ç»ç½‘ç»œæ—¶çš„æ­¥éª¤:
ç½‘ç»œç»“æ„:ç¬¬ä¸€ä»¶è¦åšçš„äº‹æ˜¯é€‰æ‹©ç½‘ç»œç»“æ„ï¼Œå³å†³å®šé€‰æ‹©å¤šå°‘å±‚ä»¥åŠå†³å®šæ¯å±‚åˆ†åˆ«æœ‰å¤š å°‘ä¸ªå•å…ƒã€‚
ç¬¬ä¸€å±‚çš„å•å…ƒæ•°å³æˆ‘ä»¬è®­ç»ƒé›†çš„ç‰¹å¾æ•°é‡ã€‚ æœ€åä¸€å±‚çš„å•å…ƒæ•°æ˜¯æˆ‘ä»¬è®­ç»ƒé›†çš„ç»“æœçš„ç±»çš„æ•°é‡ã€‚
å¦‚æœéšè—å±‚æ•°å¤§äº1ï¼Œç¡®ä¿æ¯ä¸ªéšè—å±‚çš„å•å…ƒä¸ªæ•°ç›¸åŒï¼Œé€šå¸¸æƒ…å†µä¸‹éšè—å±‚å•å…ƒçš„ä¸ªæ•°è¶Šå¤šè¶Šå¥½ã€‚
æˆ‘ä»¬çœŸæ­£è¦å†³å®šçš„æ˜¯éšè—å±‚çš„å±‚æ•°å’Œæ¯ä¸ªä¸­é—´å±‚çš„å•å…ƒæ•°ã€‚
è®­ç»ƒç¥ç»ç½‘ç»œ:
1. å‚æ•°çš„éšæœºåˆå§‹åŒ–
2. åˆ©ç”¨æ­£å‘ä¼ æ’­æ–¹æ³•è®¡ç®—æ‰€æœ‰çš„hğœƒ(ğ‘¥)
3. ç¼–å†™è®¡ç®—ä»£ä»·å‡½æ•° ğ½ çš„ä»£ç 
4. åˆ©ç”¨åå‘ä¼ æ’­æ–¹æ³•è®¡ç®—æ‰€æœ‰åå¯¼æ•°
5. åˆ©ç”¨æ•°å€¼æ£€éªŒæ–¹æ³•æ£€éªŒè¿™äº›åå¯¼æ•°
6. ä½¿ç”¨ä¼˜åŒ–ç®—æ³•æ¥æœ€å°åŒ–ä»£ä»·å‡½æ•°
"""


def load_mat():
    '''è¯»å–æ•°æ®'''
    data = loadmat('./data/ex4data1.mat')  # return a dict
    X = data['X']
    y = data['y'].flatten()

    return X, y


def plot_100_images(X):
    """éšæœºç”»100ä¸ªæ•°å­—"""
    index = np.random.choice(range(5000), 100)
    images = X[index]
    fig, ax_array = plt.subplots(10, 10, sharex=True, sharey=True, figsize=(8, 8))
    for r in range(10):
        for c in range(10):
            ax_array[r, c].matshow(images[r * 10 + c].reshape(20, 20), cmap='gray_r')
    plt.xticks([])
    plt.yticks([])
    plt.show()


def expand_y(y):
    """
    æŠŠyä¸­æ¯ä¸ªç±»åˆ«è½¬åŒ–ä¸ºä¸€ä¸ªå‘é‡ï¼Œå¯¹åº”çš„lableå€¼åœ¨å‘é‡å¯¹åº”ä½ç½®ä¸Šç½®ä¸º1
    :param y:
    :return:
    """
    result = []
    for i in y:
        y_array = np.zeros(10)
        y_array[i - 1] = 1
        result.append(y_array)
    '''
    # æˆ–è€…ç”¨sklearnä¸­OneHotEncoderå‡½æ•°
    encoder =  OneHotEncoder(sparse=False)  # return a array instead of matrix
    y_onehot = encoder.fit_transform(y.reshape(-1,1))
    return y_onehot
    '''
    return np.array(result)


def load_weight():
    """å·²è®­ç»ƒå¥½çš„æƒé‡"""
    data = loadmat('./data/ex4weights.mat')
    return data['Theta1'], data['Theta2']


def serialize(a, b):
    '''å±•å¼€å‚æ•°'''
    return np.r_[a.flatten(), b.flatten()]


def sigmoid(z):
    """æ¿€æ´»å‡½æ•°"""
    return 1 / (1 + np.exp(- z))


def deserialize(seq):
    '''æå–å‚æ•°'''
    return seq[:25 * 401].reshape(25, 401), seq[25 * 401:].reshape(10, 26)


def feed_forward(theta, X, ):
    '''å¾—åˆ°æ¯å±‚çš„è¾“å…¥å’Œè¾“å‡º'''
    t1, t2 = deserialize(theta)
    # å‰é¢å·²ç»æ’å…¥è¿‡åç½®å•å…ƒï¼Œè¿™é‡Œå°±ä¸ç”¨æ’å…¥äº†
    a1 = X
    z2 = a1 @ t1.T
    a2 = np.insert(sigmoid(z2), 0, 1, axis=1)
    z3 = a2 @ t2.T
    a3 = sigmoid(z3)

    return a1, z2, a2, z3, a3


def cost(theta, X, y):
    """ç¥ç»ç½‘ç»œçš„ä»£ä»·å‡½æ•°"""
    a1, z2, a2, z3, h = feed_forward(theta, X)
    J = 0
    for i in range(len(X)):
        first = - y[i] * np.log(h[i])
        second = (1 - y[i]) * np.log(1 - h[i])
        J = J + np.sum(first - second)
    J = J / len(X)
    '''
         # or just use verctorization
         J = - y * np.log(h) - (1 - y) * np.log(1 - h)
         return J.sum() / len(X)
    '''
    return J


def regularized_cost(theta, X, y, l=1):
    '''æ­£åˆ™åŒ–æ—¶å¿½ç•¥æ¯å±‚çš„åç½®é¡¹ï¼Œä¹Ÿå°±æ˜¯å‚æ•°çŸ©é˜µçš„ç¬¬ä¸€åˆ—'''
    t1, t2 = deserialize(theta)
    reg = np.sum(t1[:, 1:] ** 2) + np.sum(t2[:, 1:] ** 2)  # or use np.power(a, 2)
    return l / (2 * len(X)) * reg + cost(theta, X, y)


def sigmoid_gradient(z):
    """æ¿€æ´»å‡½æ•°çš„å¯¼æ•°"""
    return sigmoid(z) * (1 - sigmoid(z))


def random_init(size):
    '''ä»æœä»çš„å‡åŒ€åˆ†å¸ƒçš„èŒƒå›´ä¸­éšæœºè¿”å›sizeå¤§å°çš„å€¼'''
    return np.random.uniform(-0.12, 0.12, size)


def gradient(theta, X, y):
    '''
    unregularized gradient, notice no d1 since the input layer has no error
    return æ‰€æœ‰å‚æ•°thetaçš„æ¢¯åº¦ï¼Œæ•…æ¢¯åº¦D(i)å’Œå‚æ•°theta(i)åŒshapeï¼Œé‡è¦ã€‚
    '''
    t1, t2 = deserialize(theta)
    a1, z2, a2, z3, h = feed_forward(theta, X)
    # è¾“å‡ºå±‚é¢„æµ‹å€¼ä¸å®é™…å€¼ä¹‹é—´çš„è¯¯å·®
    d3 = h - y  # (5000, 10)
    # ç¬¬äºŒå±‚çš„é¢„æµ‹å€¼ä¸å®é™…å€¼ä¹‹é—´çš„è¯¯å·®
    d2 = d3 @ t2[:, 1:] * sigmoid_gradient(z2)  # (5000, 25)
    # ç¬¬2å±‚çš„åå¯¼æ•°
    D2 = d3.T @ a2  # (10, 26)
    # ç¬¬1å±‚çš„åå¯¼æ•°
    D1 = d2.T @ a1  # (25, 401)
    # è®¡ç®—ä»£ä»·å‡½æ•°çš„åå¯¼æ•°
    D = (1 / len(X)) * serialize(D1, D2)  # (10285,)
    return D


def regularized_gradient(theta, X, y, l=1):
    """ä¸æƒ©ç½šåç½®å•å…ƒçš„å‚æ•°ï¼Œæ­£åˆ™åŒ–ç¥ç»ç½‘ç»œ"""
    # a1, z2, a2, z3, h = feed_forward(theta, X)
    D1, D2 = deserialize(gradient(theta, X, y))
    t1[:, 0] = 0
    t2[:, 0] = 0

    reg_D1 = D1 + (l / len(X)) * t1
    reg_D2 = D2 + (l / len(X)) * t2

    return serialize(reg_D1, reg_D2)


def nn_training(X, y):
    """Learning parameters using fmincg ä¼˜åŒ–å‚æ•°"""
    init_theta = random_init(10285)  # 25*401 + 10*26

    res = opt.minimize(fun=regularized_cost,
                       x0=init_theta,
                       args=(X, y, 1),
                       method='TNC',
                       jac=regularized_gradient,
                       options={'maxiter': 400})
    return res


def accuracy(res, X, y):
    _, _, _, _, h = feed_forward(res.x, X)
    y_pred = np.argmax(h, axis=1) + 1
    print(classification_report(y, y_pred))


if __name__ == "__main__":
    X, y = load_mat()
    X = np.insert(X, 0, 1, axis=1)
    y = expand_y(y)
    t1, t2 = load_weight()
    theta = serialize(t1, t2)
    # å‰å‘ä¼ æ’­
    a1, z2, a2, z3, h = feed_forward(theta, X)
    J = cost(theta, X, y)
    Jy = regularized_cost(theta, X, y)
    # åå‘ä¼ æ’­
    D = gradient(theta, X, y)
    # æ­£åˆ™åŒ–æƒ©ç½š
    rD = regularized_gradient(theta, X, y)
    # å‚æ•°ä¼˜åŒ–
    res = nn_training(X, y)
    # accuracy(res, X, y)
    pass
    # plot_100_images(X)
